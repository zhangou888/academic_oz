reg1$robse <- vcovHC(reg1, type = "HC1")
# Heteroscedasticity-Consistent Covariance Matrix Estimation
# from lib(sandwich)
reg1$robse <- vcovHC(reg1, type = "HC1")
# Heteroscedasticity-Consistent Covariance Matrix Estimation
# from lib(sandwich)
reg1$robse <- vcovHC(reg1, type = "HC1")
# coeftest is a generic function for
# performing z and (quasi-) t Wald tests of estimated coefficients.
coeftest(reg1, reg1$robse)
# --- Predicted values/Residuals --- #
# after running the regression
prestige_hat <- fitted(reg1) %>% # predicted values
as.data.frame()
prestige_resid <- residuals(reg1) %>% # residuals
as.data.frame()
prestige_hat
## --- Dummy regression with no interactions (analysis of covariance, fixed effects)
reg2 <- lm(prestige ~ education + log2(income) + type,
data = Prestige)
summary(reg2)
summary(reg1)
summary(reg2)
# reordering factor variables
Prestige$type <- with(Prestige, factor(type,levels=c("bc","wc","prof")))
Prestige$type
## --- Dummy regression with interactions (analysis of covariance, fixed effects)
reg3 <- lm(prestige ~ type*(education + log2(income)),
data = Prestige)
summary(reg3)
# Other ways to run the same model
reg3a <- lm(prestige ~ education + log2(income) + type +
log2(income):type + education:type,
data = Prestige)
summary(reg3a)
reg1 <- lm(prestige ~ education + income + type,
data= Prestige)
resitualPlot(reg1)
residualPlot(reg1)
## --- Dummy regression with interactions (analysis of covariance, fixed effects)
reg3 <- lm(prestige ~ type*(education + log2(income)),
data = Prestige)
summary(reg3)
# Other ways to run the same model
reg3a <- lm(prestige ~ education + log2(income) + type +
log2(income):type + education:type,
data = Prestige)
summary(reg3a)
reg3b <- lm(prestige ~ education*type + log2(income)*type,
data = Prestige)
summary(reg3b)
reg2 <- lm(prestige ~ education + log2(income) + type,
data= Prestige)
residualPlot(reg2)
# Residuals vs fitted only
residualPlots(reg1, ~ 1, fitted=TRUE)
# Residuals vs education only
residualPlots(reg1, ~ education, fitted=FALSE)
# ----  Influential variables- added-variables plots.
reg1 <- lm(prestige ~ education + income + type,
data = Prestige)
avPlots(reg1, id.n=2, id.cex=0.7)
# ---- Outlier - QQ-Plots
reg1 <- lm(prestige ~ education + income + type,
data = Prestige)
qqPlot(reg1, id.n=3)
# null for the Bonferonni adjusted outlier test-the observation is an outlier.
# Here observation related to 'medical.technicians' is an outlier.
outlierTest(reg1)
# --- High leverage (hat) point
reg1 <- lm(prestige ~ education + income + type,
data = Prestige)
influenceIndexPlot(reg1, id.n=3)
reg1a <- update(prestige.reg4, subset=rownames(Prestige) != "general.managers")
reg4 <- lm(prestige ~ education + income + type,
data= Prestige)
residualPlot(reg4)
# Residuals vs fitted only
# o get a plot against fitted values only, use the arguments terms = ~ 1
residualPlots(reg4, ~ 1, fitted=TRUE)
# Residuals vs fitted only
# o get a plot against fitted values only, use the arguments terms = ~ 1
residualPlots(reg4, ~ 1, fitted=TRUE)
residualPlot(reg4)
# Residuals vs fitted only
# o get a plot against fitted values only, use the arguments terms = ~ 1
residualPlots(reg4, ~ 1, fitted=TRUE)
# Residuals vs education only
residualPlots(reg4, ~ education, fitted=FALSE)
# ----  Influential variables- added-variables plots.
reg5 <- lm(prestige ~ education + income + type,
data = Prestige)
# id.n - id most influential observation
# id.cex - font size for id.
avPlots(reg5, id.n=2, id.cex=0.7)
# ---- Outlier - QQ-Plots
reg6 <- lm(prestige ~ education + income + type,
data = Prestige)
# # id.n - id most influential observation
qqPlot(reg6, id.n=3)
# ---- Outliers - Bonferonni Test --- ##
reg7 <- lm(prestige ~ education + income + type,
data = Prestige)
# null for the Bonferonni adjusted outlier test-the observation is an outlier.
# Here observation related to 'medical.technicians' is an outlier.
outlierTest(reg7)
# --- High leverage (hat) point
reg8 <- lm(prestige ~ education + income + type,
data = Prestige)
# Hat-points identify influential observations (have a high impact on the
# predictor variables)
influenceIndexPlot(reg8, id.n=3)
reg1a <- update(reg8, subset=rownames(Prestige) != "general.managers")
reg1b <- update(reg8,
subset= !(rownames(Prestige) %in% c("general.managers",
"medical.technicians")))
influenceIndexPlot(reg1a, id.n=3)
influenceIndexPlot(reg1b, id.n=3)
# --------  Influence Plots -------------- #
reg1 <- lm(prestige ~ education + income + type, data=Prestige)
# Creates a bubble-plot combining the display of Studentized residuals,
# hat-values, and Cook's Distance (represented in circles)
influencePlot(reg1, id.n=3)
# ----- Testing for normality  ------- #
reg1 <- lm(prestige ~ eduataion + income + type, data=Prestige)
qqPlot(reg1)
# ----- Testing for normality  ------- #
reg1 <- lm(prestige ~ educataion + income + type, data=Prestige)
# ----- Testing for normality  ------- #
reg1 <- lm(prestige ~ education + income + type, data=Prestige)
qqPlot(reg1)
# look for the tails, points should be close to the line or within the
# confidence intervals.
# Quantile plots compare the studentized residuals vs a t-distribution
# other Tests: shapiro.test(), mshapiro.test() in library(mvnormtest)-library(ts)
shapiro.test(reg1)
# ------- Testing for heteroskedasticity ------ #
reg1 <- lm(prestige ~ education + income + type, data=Prestige)
# non-constant variance score test
ncvTest(reg1)
# Breush/Pagan and Cook/Weisberg score test for non-constant error variance.
# Null is constant variance, see also residualPlots(reg1)
residualPlots(reg1)
# Residuals vs education only
residualPlots(reg4, ~ education, fitted=FALSE)
residualPlot(reg4)
reg4 <- lm(prestige ~ education + income + type,
data= Prestige)
residualPlot(reg4)
# ------- Testing for heteroskedasticity ------ #
reg1 <- lm(prestige ~ education + income + type, data=Prestige)
# Breush/Pagan and Cook/Weisberg score test for non-constant error variance.
# Null is constant variance, see also residualPlots(reg1)
residualPlots(reg1)
reg1
reg4
# -----------Testing for multicolinearity ------------- ##
# A gvif > 4 suggests collineartiy.
# when there are strong linear relationships among the predictor in a regression
# analysis, the precision of the estimated regression coefficients in linear
# model declines compared to what it would have been were the predictors uncorrelated
# with each other" (Fox: 359).
vif(reg1)
blogdown:::serve_site()
#############################################################################
#                                                                          ##
##          Project: r-statistics.co Outlier Analysis                      ##
##                                                                         ##
##-------------------------------------------------------------------------##
##          Programmer: Selva Prabhakaran                                  ##
##          Request Date: 09-15-2020                                       ##
##          Initial Code:                                                  ##
##          Goals:                                                         ##
##          Input:                                                         ##
##          Output:                                                        ##
##          Note: This chapter explains the purpose of some of the most    ##
##         commonly used outlier analysis and how to implement them in R   ##
##         http://r-statistics.co/Outlier-Treatment-With-R.html
##-------------------------------------------------------------------------##
##          Modification History:                                          ##
##          When:                                                          ##
##          Who:                                                           ##
##          Change:                                                        ##
##-------------------------------------------------------------------------##
## Step 1: Set work directory
rm(list=ls())
## Step 2: load required packages
packages <- c("tidyverse","mlbench","mice","Hmisc","DMwR",
"rpart","mice","outliers")
packages <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x)
library(x, character.only = TRUE)
}
})
library(mlbench)
library(mice)
## Step 3: Set up key libraries and source code
proj.path = file.path("c:/temp/stat ");
data.path = file.path(proj.path,"data/");
out.path = file.path(proj.path,"out/");
setwd(proj.path)
# in regression models.
## -- Example -- ##
# Inject outliers into data.
# original data
cars1 <- cars[1:30, ]
# introduce outliers.
cars_outliers <- data.frame(speed=c(19,19,20,20,20),
dist=c(190, 186, 210, 220, 218))
cars2 <- rbind(cars1, cars_outliers)  # data with outliers.
# Plot of data with outliers.
par(mfrow=c(1, 2))
plot(cars2$speed, cars2$dist,
xlim=c(0, 28), ylim=c(0, 230),
main="With Outliers",
xlab="speed", ylab="dist",
pch="*", col="red", cex=2)
cars_outliers
## ---------- Detect outliers ------ ##
# 1.1 Univariate approach
# Criterion 1: 1.5 IQR
# Continuous Variable-outliers are those observations that lie outside 1.5 * IQR,
# IQR- 'Inter Quartile Range' is the difference between 75th and 25th quartiles.
url <- "https://raw.githubusercontent.com/selva86/datasets/master/ozone.csv"
# alternate source:  https://raw.githubusercontent.com/selva86/datasets/master/ozone.csv
inputData <- read.csv(url)  # import data
# outlier values.
outlier_values <- boxplot.stats(inputData$pressure_height)$out
boxplot(inputData$pressure_height, main="Pressure Height", boxwex=0.1)
mtext(paste("Outliers: ", paste(outlier_values, collapse=", ")), cex=0.6)
# 1.2 Bivariate approach
url <- "https://raw.githubusercontent.com/selva86/datasets/master/ozone.csv"
ozone <- read.csv(url)
# For categorical variable
boxplot(ozone_reading ~ Month, data=ozone,
main="Ozone reading across months")  # clear pattern is noticeable.
# this may not be significant, as day of week variable is a subset of the month var.
boxplot(ozone_reading ~ Day_of_week, data=ozone,
main="Ozone reading for days of week")
# For continuous variable (convert to categorical if needed.)
boxplot(ozone_reading ~ pressure_height, data=ozone,
main="Boxplot for Pressure height (continuos var) vs Ozone")
boxplot(ozone_reading ~ cut(pressure_height,
pretty(inputData$pressure_height)),
data=ozone, main="Boxplot for Pressure height (categorial) vs Ozone",
cex.axis=0.5)
# =============== 1.3 Multivariate Model Approach =====================#
# 1.3.1 Cooks Distance
# Cook's distance is a measure computed with respect to a given regression model
# and therefore is impacted only by the X variables included in the model.
mod <- lm(ozone_reading ~ ., data=ozone)
cooksd <- cooks.distance(mod)
# plot cook's distance
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")
# add cutoff line (4)
abline(h = 4*mean(cooksd, na.rm=T), col="red")
# add labels
text(x=1:length(cooksd)+1, y=cooksd,
labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")
# find out the influential rows from the original data
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])  # influential row numbers
head(ozone[influential, ])  # influential observations.
##  --------- 2.1 Outliers Test ------------  ##
car::outlierTest(mod)
set.seed(1234)
y=rnorm(100)
outlier(y)
#> [1] 2.548991
outlier(y,opposite=TRUE)
#> [1] -2.345698
dim(y) <- c(20,5)  # convert it to a matrix
outlier(y)
#> [1] 2.415835 1.102298 1.647817 2.548991 2.121117
outlier(y,opposite=TRUE)
# Compute the normalized scores based on "z", "t", "chisq" etc
# Find out observations that lie beyond a
# given percentile based on a given score.
set.seed(1234)
x = rnorm(10)
scores(x)  # z-scores => (x-mean)/sd
scores(x, type="chisq")  # chi-sq scores => (x - mean(x))^2/var(x)
#> [1] 0.68458034 0.44007451 2.17210689 3.88421971 0.66539631  . . .
scores(x, type="t")  # t scores
scores(x, type="chisq", prob=0.9)  # beyond 90th %ile based on chi-sq
scores(x, type="chisq", prob=0.95)  # beyond 95th %ile
scores(x, type="z", prob=0.95)  # beyond 95th %ile based on z-scores
scores(x, type="t", prob=0.95)  # beyond 95th %ile based on t-scores
x <- ozone$pressure_height
#############################################################################
#                                                                          ##
##          Project: Outliers detection in R                               ##
##                                                                         ##
##-------------------------------------------------------------------------##
##          Programmer: Anthoine Setwey                                    ##
##          Request Date: 10-21-2020                                       ##
##          Initial Code:                                                  ##
##          Goals:                                                         ##
##          Input:                                                         ##
##          Output:                                                        ##
##          Note: This chapter explains the purpose of some of the most    ##
##         commonly used outlier analysis and how to implement them in R   ##
##          https://www.statsandr.com/blog/outliers-detection-in-r/        ##
##-------------------------------------------------------------------------##
##          Modification History:                                          ##
##          When:                                                          ##
##          Who:                                                           ##
##          Change:                                                        ##
##-------------------------------------------------------------------------##
## Step 1: Set work directory
rm(list=ls())
## Step 2: load required packages
packages <- c("tidyverse","ggplot2","outliers","EnvStats","mvoutlier")
packages <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x)
library(x, character.only = TRUE)
}
})
library(ggplot2)
library(outliers)
## Step 3: Set up key libraries and source code
proj.path = file.path("c:/temp/stat ");
data.path = file.path(proj.path,"data/");
out.path = file.path(proj.path,"out/");
setwd(proj.path)
## Step 4: Read-in data.
## ------- Descriptive statistics ----------##
# Minimum and maximum
dat <- ggplot2::mpg
summary(dat$hwy)
# Min and max
min(dat$hwy)
max(dat$hwy)
## -------- Histogram  -----------##
# Another basic way to detect outliers is to draw a histogram of the data.
# Using R base (with the number of bins corresponding to
# the square root of the number of observations in order
# to have more bins than the default option):
hist(dat$hwy,xlab = "hwy",
main = "Histogram of hwy",
breaks = sqrt(nrow(dat))) # set number of bins
# Using R base:
boxplot(dat$hwy, ylab = "hwy")
# using ggplot2:
ggplot(dat) + aes(x = "", y = hwy) +
geom_boxplot(fill = "#0c4c8a") +
theme_minimal()
# Example data.
ex1 <- data.frame(gender=c("M","F","F","M","M"),
age=c(15, 20, 25, 27, 4000))
ex1
# Example data.
ex1 <- data.frame(id=c(1,2,3,4,5),
gender=c("M","F","F","M","M"),
age=c(15, 20, 25, 27, 4000))
ex1
# Example data.
ex1 <- data.frame(id=c(1,2,3,4,5),
gender=c("M","F","F","M","M"),
age=c(15, 20, 400, 27, 50))
ex1 %>% order_by(age)
order_by(ex1,age)
# Example data.
ex1 <- data.frame(id=c(1,2,3,4,5),
gender=c("M","F","F","M","M"),
age=c(15, 20, 400, 27, 50))
order_by(ex1,age)
arrange(ex1,age)
# using ggplot2:
ggplot(dat) + aes(x = "", y = hwy) +
geom_boxplot(fill = "#0c4c8a") +
theme_minimal()
median(dat$hwy)
mad(dat$hwy)
lower_bound <- median(dat$hwy) - 3 * mad(dat$hwy)
lower_bound
upper_bound <- median(dat$hwy) + 3 * mad(dat$hwy)
upper_bound
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
xaringan:::inf_mr()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
#############################################################################
#                                                                          ##
##          Project: r-statistics.co Outlier Analysis                      ##
##                                                                         ##
##-------------------------------------------------------------------------##
##          Programmer: Selva Prabhakaran                                  ##
##          Request Date: 09-15-2020                                       ##
##          Initial Code:                                                  ##
##          Goals:                                                         ##
##          Input:                                                         ##
##          Output:                                                        ##
##          Note: This chapter explains the purpose of some of the most    ##
##         commonly used outlier analysis and how to implement them in R   ##
##         http://r-statistics.co/Outlier-Treatment-With-R.html
##-------------------------------------------------------------------------##
##          Modification History:                                          ##
##          When:                                                          ##
##          Who:                                                           ##
##          Change:                                                        ##
##-------------------------------------------------------------------------##
## Step 1: Set work directory
rm(list=ls())
## Step 2: load required packages
packages <- c("tidyverse","mlbench","mice","Hmisc","DMwR",
"rpart","mice","outliers")
packages <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x)
library(x, character.only = TRUE)
}
})
library(mlbench)
library(mice)
## Step 3: Set up key libraries and source code
proj.path = file.path("c:/temp/stat ");
data.path = file.path(proj.path,"data/");
out.path = file.path(proj.path,"out/");
setwd(proj.path)
## Step 4: Read-in data.
#------------ Section 2 ------------- #
## Outlier Treatment
# Outliers in data can distort predictions and affect the accuracy,
# if you don't detect and handle them appropriately especially.
# in regression models.
## -- Example -- ##
# Inject outliers into data.
# original data
cars1 <- cars[1:30, ]
# introduce outliers.
cars_outliers <- data.frame(speed=c(19,19,20,20,20),
dist=c(190, 186, 210, 220, 218))
cars2 <- rbind(cars1, cars_outliers)  # data with outliers.
# Plot of data with outliers.
par(mfrow=c(1, 2))
plot(cars2$speed, cars2$dist,
xlim=c(0, 28), ylim=c(0, 230),
main="With Outliers",
xlab="speed", ylab="dist",
pch="*", col="red", cex=2)
# regression reference line
abline(lm(dist ~ speed, data=cars2), col="blue", lwd=3, lty=2)
# Plot of original data without outliers. Note the change in slope (angle) of best fit line.
plot(cars1$speed, cars1$dist,
xlim=c(0, 28), ylim=c(0, 230),
main="Outliers removed \n A much better fit!",
xlab="speed", ylab="dist",
pch="*", col="red", cex=2)
abline(lm(dist ~ speed, data=cars1), col="blue", lwd=3, lty=2)
url <- "https://raw.githubusercontent.com/selva86/datasets/master/ozone.csv"
# alternate source:  https://raw.githubusercontent.com/selva86/datasets/master/ozone.csv
inputData <- read.csv(url)  # import data
# outlier values.
outlier_values <- boxplot.stats(inputData$pressure_height)$out
boxplot(inputData$pressure_height, main="Pressure Height", boxwex=0.1)
mtext(paste("Outliers: ", paste(outlier_values, collapse=", ")), cex=0.6)
url <- "https://raw.githubusercontent.com/selva86/datasets/master/ozone.csv"
ozone <- read.csv(url)
# For categorical variable
boxplot(ozone_reading ~ Month, data=ozone,
main="Ozone reading across months")  # clear pattern is noticeable.
# this may not be significant, as day of week variable is a subset of the month var.
boxplot(ozone_reading ~ Day_of_week, data=ozone,
main="Ozone reading for days of week")
# this may not be significant, as day of week variable is a subset of the month var.
boxplot(ozone_reading ~ Day_of_week, data=ozone,
main="Ozone reading for \n days of week")
# this may not be significant, as day of week variable is a subset of the month var.
boxplot(ozone_reading ~ Day_of_week, data=ozone,
main="Ozone reading for \n days of week")
# For continuous variable (convert to categorical if needed.)
boxplot(ozone_reading ~ pressure_height, data=ozone,
main="Boxplot for Pressure \n height (continuos var) vs Ozone")
boxplot(ozone_reading ~ cut(pressure_height,
pretty(inputData$pressure_height)),
data=ozone, main="Boxplot for Pressure \n height (categorial) vs Ozone",
cex.axis=0.5)
xaringan:::inf_mr()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
xaringan:::inf_mr()
blogdown:::serve_site()
xaringan:::inf_mr()
blogdown:::serve_site()
xaringan:::inf_mr()
blogdown:::serve_site()
xaringan:::inf_mr()
blogdown:::serve_site()
xaringan:::inf_mr()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
xaringan:::inf_mr()
xaringan:::inf_mr()
blogdown:::serve_site()
blogdown:::serve_site()
xaringan:::inf_mr()
xaringan:::inf_mr()
