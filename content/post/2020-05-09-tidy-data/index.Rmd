---
title: 'Introducing Tidyverse-Part 1:Tidy Data'
author: Ou Zhang
date: '2020-05-09'
slug: Tidy data
draft: no
categories: 
  - R
  - Data science
tags:
  - R
  - Data Science
subtitle: ''
summary: ''
authors: []
lastmod: '2020-05-09T23:53:01-05:00'
featured: no
disable_jquery: no
image:
  caption: ''
  focal_point: 'Smart'
  preview_only: no
projects: []
output:
  blogdown::html_page:
    toc: false
    number_sections: yes
    toc_depth: 3
---

```{r set-global-options, echo = FALSE}
knitr::opts_chunk$set(eval = TRUE, 
                      echo = FALSE, 
                      cache = FALSE,
                      include = TRUE,
                      collapse = FALSE,
                      dependson = NULL,
                      engine = "R", # Chunks will always have R code, unless noted
                      error = TRUE,
                      # root.dir = "C:/Users/uzhanou/Documents/R/markdown/Serena/",
                      fig.path = "figure/",  # Set the figure options
                      fig.align = "center", 
                      fig.width = 6,
                      fig.height = 6)
```

```{r silent-packages, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE，cache=TRUE}
## Step 2: load required packages 
packages <- c("tidyverse","rmarkdown","knitr")
packages <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x)
    library(x, character.only = TRUE)
  }
})

# install.packages("devtools")
library(devtools)
devtools::install_github("garrettgman/DSR")
devtools::install_github("uc-cfss/rcfss")

library(tidyr)
library(dplyr)
library(DSR)
library(rcfss)

```

In an ideal world, a data analysis process is as simple as-`**read in data, select a suitable model to fit in data, obtain statistical estimates, and finally, interpret the analysis results**`. Sounds simple and straight foward, isn't it? 

But, in reality, it’s often not that simple!Data is always messy and often times we need to clean our data before we can make any sense of it. Moreover, some researchers found that more than `**80%**` of data analysis is actually spent on data preparation or data manipulation (Dasu & Johnson, 2003), so that the data is transformed int a usable format before you even think about analysis.

Therefore, data cleaning or data wrangling is utmost important for any data analysis or data science project.

In the early 2010s, [Hadley Wickham](http://hadley.nz/) invented one of the most important R package series - [Tidyverse](https://www.tidyverse.org/).

```{r fig1, out.width='20%', fig.align='center', fig.pos='h', fig.cap='Tidyverse',echo = FALSE}

    knitr::include_graphics("img/tidyverse.png", error = FALSE)

```

The `**tidyverse**` is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. It mainly focuses on the data wrangling steps including data import/export, data format conversion, data wrangling or data tidying. The ideal data analysis process, or the standard process explained by Hadley looks like the flow chart below.

```{r fig2, out.width='70%', fig.align='center', fig.pos='h', fig.cap='data analysis flow',echo = FALSE}

    knitr::include_graphics("img/r4ds_data-science.png", error = FALSE)

```

The idea of data tidying is the `**first step**` and standard way to structure datasets for later data analysis. 

On internet, you can easily googled tons of information and websites introducing this R-package collection. However, most of the introductions, only spend one or two paragraphs to depict the definition of `**Tidy data**` then move on to the command line examples and description of relevant package applications. Only Hadley own [R for Data Science](https://r4ds.had.co.nz) book, gives an entire chapter to give a detailed story about `**Tidy data**`. Because of its importance, Hadley published a paper, only introducing the definition of `**Tidy data**`.

You can find the paper from this link: [Tidy data](https://www.jstatsoft.org/index.php/jss/article/view/v059i10/v59i10.pdf).

The paper itself claims the above definitions are [**Codd 3rd normal form**](https://en.wikipedia.org/wiki/Third_normal_form).


As a data scientist, personally I think the Tidy data is more than just great. It is not just an idea, but it provides a comprehensive `**“philosophy of data”**` in terms of data handling, and data science. For that reason, I would like to write a bit on the meaning and history of the phrase `**tidy data**` as my first ever blog series of `**Tidyverse**` introduction.    

# What is Tidy data？

The first question is-What is tidy data?

Tidy data is a specific way of organizing data into a consistent format which plugs into the tidyverse set of packages for R. It is not the only way to store data and there are reasons why you might not store data in this format, but eventually you will probably need to convert your data to a tidy format in order to efficiently analyze it.

There are three rules which make a dataset tidy:

<!-- * Each variable must have its own column -->
<!-- * Each observation must have its own row -->
<!-- * Each value must have its own cell -->


```{r fig3, out.width='75%', fig.align='center', fig.pos='h', fig.cap='data analysis flow',echo = FALSE}

    knitr::include_graphics("img/tidy_data.png", error = FALSE)

```

Tidy data is particularly well suited for vectorized programming languages like R (R Core Team 2014), because the layout ensures that values of different variables from the same observation are always paired.

Please note that this concept was already well known in statistics and called a `**data matrix**`. For example:

  > A standard method of displaying a multivariate set of data is in the form of a data matrix in which rows correspond to sample individuals and columns to variables, so that the entry in the ith row and jth column gives the value of the jth variate as measured or observed on the ith individual.

  > _Krzanowski, W. J., F. H. C. Marriott, Multivariate Analysis Part 1, Edward Arnold, 1994, page 1._
 
# Why is it important?
So, the 2nd question is-why is this Tidy data structure important?

The short answer is in three folds.

* Organizing datasets as tidy data makes data cleaning efforts easier
* Broad range of analytical tools are built upon the assumption to consume tidy data
* Sharing tidy data increases re-use

The figure below displays the tools for tidy data in the Tidyverse package series.

```{r fig4, out.width='75%', fig.align='center', fig.pos='h', fig.cap='Tools for Tidy data',echo = FALSE}

    knitr::include_graphics("img/tools_for_tidy.jpg", error = FALSE)

```

# Fixed variable vs. Measured variable

In general, two types of varaibles exist in the tidy data structure, fixed variable and measured variable.

* `**Fixed variable**` - Fixed variables describe the experimental design and are known in advance.  

* `**Measured variable**` - Measured variables are what we actually measured in the study.

In the Tidy data structure, fixed variables should come `**first**`, followed by measured variables, each ordered so that related variables are contiguous. Rows can then be ordered by the first variable, breaking ties with the second and subsequent (fixed) variables.

# Is such a data set **tidy**?  
While starting data analysis, data scientists should ask themselves a big question before moving on to the real data analysis. 

This question is: 

> Is this data set **tidy**? 

Let's look at a couple of data structures and ask yourself this question.

## Example 1:

```{r fig5, out.width='75%', fig.align='center', fig.pos='h', fig.cap='data 1',echo = FALSE}

    knitr::include_graphics("img/data1.png", error = FALSE)

```
So, is this data structure a tidy data?

The short answer is `**No, it's not tidy data**`. This is because variable 2 to 4 (column 2-4) are all stock price. And according to tidy data rule No. 1-_Each variable must have its own column_. All three variables should be transform into a single variable to store stock price values and create a new variable to indicate stock names.

## Example 2:

Let's look at the 2nd data example. 

```{r fig6, out.width='70%', fig.align='center', fig.pos='h', fig.cap='data 2',echo = FALSE}

    knitr::include_graphics("img/data2.png", error = FALSE)

```
So, is this data structure a tidy data?

The answer is `**Yes, it is tidy data**`. And you can tell that the data structure 2 meet all three conditions of tidy data. Moreover, it is the data structure 1 after tidy data transformation. 

## Example 3:

Let's look at the 3rd data example to reinforce the tidy data idea. 

```{r fig7, out.width='70%', fig.align='center', fig.pos='h', fig.cap='data 3',echo = FALSE}

    knitr::include_graphics("img/data3.png", error = FALSE)

```
So, is this data structure a tidy data?

`**Yes, it is tidy data**`. And you can tell that the data structure 3 is similar to the data structure 2 with only 3rd variable differences. It meets all three conditions of tidy data as well.  

## Code Examples  

So, you've seen some data examples and let's run some dynamic codes as tidy data examples. The code below display the same data with 4 different structures. One dataset (tidy data structure) is much easier to work with in R than others. 


```{r data1}
# dataset 1 (tidy data)
(table1)
```
Data 1 is tidy data structure. This is because each variable has its own column (i.e., country, year, cases, and population). And each observation has its own row. Finally, each value has its own cell.

```{r data2}
(table2)
```
Data 2 intermingles the values of population and cases in the same column-value. So, data 2 is not tidy data.

```{r data3}

(table3)

```
The case and population variables in data 3 are in the same column.

```{r data4}

(table4)

```
data 4 only includes the case variable and the population variable is missing.

```{r data5}

(table5)

```
data 5 only includes the population variable, and the case variable is missing in the dataset.


# Traditional measurement testing dataset  

As psychometricians, the data we usually encounter is the traditional measurement testing data. In order to fit the data into the traditional IRT or CTT software (i.e., WINSTEPS),  the data structures are either item score matrix, 

```{r fig8, out.width='60%', fig.align='center', fig.pos='h', fig.cap='measurement data type 1-item score',echo = FALSE}
    knitr::include_graphics("img/measure_data1.JPG", error = FALSE)
```

or item response matrix,

```{r fig9, out.width='60%', fig.align='center', fig.pos='h', fig.cap='measurement data type 1-item responses',echo = FALSE}
    knitr::include_graphics("img/measure_data2.JPG", error = FALSE)
```

These 2 data structures are `**NOT**` tidy data. 

Is this a big problem for psychometrics using tidy data structure?

The answer is `**NO**`. 

For the psychometrics, we can still apply tidy data structure in our works, because psychometrician or data scientist could always develop a standard data conversion module to transform the standard tidy data structure to the special data format customized for the traditional testing statistics software usage.


