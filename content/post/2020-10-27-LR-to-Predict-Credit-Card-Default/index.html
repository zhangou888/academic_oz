<link href="index_files/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="index_files/anchor-sections-1.0/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#data"><span class="toc-section-number">1</span> Data</a></li>
<li><a href="#income-balance-default"><span class="toc-section-number">2</span> Income, Balance &amp; Default</a></li>
<li><a href="#model-selection"><span class="toc-section-number">3</span> Model Selection</a></li>
<li><a href="#diagnosis"><span class="toc-section-number">4</span> Diagnosis</a></li>
<li><a href="#noteworthy"><span class="toc-section-number">5</span> Noteworthy</a></li>
<li><a href="#model-cross-validation"><span class="toc-section-number">6</span> Model Cross Validation</a></li>
<li><a href="#parameter-selection"><span class="toc-section-number">7</span> Parameter Selection</a></li>
</ul>
</div>

<p>Logistic regression model is widely used for group classification. In education or social science, it has been used to classify students/individuals to different groups.</p>
<p>In the finance industry, logistic regression model is also quite useful to identify/classify individual’s group status (i.e. Y) according his/her other features (i.e., Xs parameters).</p>
<p>This post originally came from James Hilton Jr. who used ‘Default’ data from the book <An Introduction to Statistical Learning: With Applications in R> and corresponding R-package-“<a href="https://cran.r-project.org/web/packages/ISLR/index.html">ISLR</a>”.</p>
<p>All I am doing for this post is to understand how the logistic regression model is being used in the finance industry. It seems fun to me to see the same model is used by simply switching different <strong>X</strong> and <strong>Y</strong>.</p>
<p>You can find his original post <a href="https://rstudio-pubs-static.s3.amazonaws.com/124689_053566cefb744fa4bb4f35011f5b5e0f.html">here</a>.</p>
<p>So, without further ado, let’s begin.</p>
<div id="data" class="section level1">
<h1><span class="header-section-number">1</span> Data</h1>
<p>The <code>Default</code> data set resides in the <code>ISLR</code> package of the R programming language. It contains selected variables and data for 10,000 credit card users.</p>
<p>Some of the variables present in the default data set are:</p>
<ul>
<li><p>student - A binary factor containing whether or not a given credit card holder is a student.</p></li>
<li><p>income - The gross annual income for a given credit card holder.</p></li>
<li><p>balance - The total credit card balance for a given credit card holder.</p></li>
<li><p>default - A binary factor containing whether or not a given user has defaulted on his/her credit card.</p></li>
</ul>
<p>The goal of this investigation is <strong>to fit a model such that the relevant predictors of credit card default are elucidated given these variables</strong>. You can find the data structure from below section.</p>
<pre class="r"><code>head(Default)</code></pre>
<pre><code>##   default student   balance    income
## 1      No      No  729.5265 44361.625
## 2      No     Yes  817.1804 12106.135
## 3      No      No 1073.5492 31767.139
## 4      No      No  529.2506 35704.494
## 5      No      No  785.6559 38463.496
## 6      No     Yes  919.5885  7491.559</code></pre>
</div>
<div id="income-balance-default" class="section level1">
<h1><span class="header-section-number">2</span> Income, Balance &amp; Default</h1>
<p>So, the key variables in the <code>Default</code> data are <strong>income</strong>, <strong>balance</strong>, and credit card default (<strong>default</strong>).</p>
<p>The Key question is-“Is there a relationship between income, balance, and student status such that one, two, or all of these might be used to predict credit card default?”</p>
<p>For the illustration purpose, first, the necessary packages and data are loaded to R.</p>
<pre class="r"><code>library(ISLR)
library(dplyr)
library(ggvis)
library(boot)</code></pre>
<p>Then, a scatterplot and a box-plot are created by <code>ggplot2</code> to find the potential relationship between variables.</p>
<p>From the scatter plot, it seem to suggest that there is a relationship between <code>credit card balance</code> and <code>default</code>, while <code>income</code> is not related. This relationship is further confirmed by the boxplot below between <code>credit card baland</code> and <code>default</code>.</p>
<pre class="r"><code># Basic scatter plot
ggplot(Default, aes(x=balance, y=income, shape=default, color=default)) + geom_point()</code></pre>
<p><img src="figure/scatterplot%20credit_balance_default-1.png" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(Default) + aes(x = default, y = balance, color=default) +
  geom_boxplot(outlier.colour=&quot;red&quot;, outlier.shape=2,
                outlier.size=1) </code></pre>
<p><img src="figure/boxplot%20credit_balance_default-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="model-selection" class="section level1">
<h1><span class="header-section-number">3</span> Model Selection</h1>
<p>Based on above plots, it suggests that <code>credit card balance</code>, but not <code>income</code>, is a <strong>useful predictor</strong> of default status. However, to be thorough in the investigation we will begin by fitting all parameters to a model of logistic form.</p>
<p>The logistic regression model is selected to fit in the credit card data because it is:</p>
<ol style="list-style-type: decimal">
<li>highly interpretable</li>
<li>the model does well when the number of parameters is low compared to N observations</li>
<li>relatively quick operating time in R and</li>
<li>fits the binary (default/non default) nature of the problem well.</li>
</ol>
You can find the model equation below.
<div>
<p><span class="math display">\[p(X)=\frac{e^{\beta_0}+\beta_1X_1+...+\beta_pX_p}{1+e^{\beta_0}+\beta_1X_1+...+\beta_pX_p}\]</span></p>
</div>
<p>This model yields the following coefficients and model information.</p>
<pre class="r"><code>glm(default~balance + student + income, family = &quot;binomial&quot;, data = Default)</code></pre>
<pre><code>## 
## Call:  glm(formula = default ~ balance + student + income, family = &quot;binomial&quot;, 
##     data = Default)
## 
## Coefficients:
## (Intercept)      balance   studentYes       income  
##  -1.087e+01    5.737e-03   -6.468e-01    3.033e-06  
## 
## Degrees of Freedom: 9999 Total (i.e. Null);  9996 Residual
## Null Deviance:       2921 
## Residual Deviance: 1572  AIC: 1580</code></pre>
</div>
<div id="diagnosis" class="section level1">
<h1><span class="header-section-number">4</span> Diagnosis</h1>
<p>An <strong>ANOVA</strong> test using Chi-Squared and the summary statistic p-values suggests that both balance and student status are useful for predicting default rates. (i.e both the Chi-Squared and p-values are statistically significant.)</p>
<pre class="r"><code>my_logit &lt;- glm(default~balance + student + income, family = &quot;binomial&quot;, data = Default)
anova(my_logit, test = &quot;Chisq&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: default
## 
## Terms added sequentially (first to last)
## 
## 
##         Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    
## NULL                     9999     2920.7              
## balance  1  1324.20      9998     1596.5 &lt; 2.2e-16 ***
## student  1    24.77      9997     1571.7 6.459e-07 ***
## income   1     0.14      9996     1571.5    0.7115    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(my_logit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = default ~ balance + student + income, family = &quot;binomial&quot;, 
##     data = Default)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4691  -0.1418  -0.0557  -0.0203   3.7383  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -1.087e+01  4.923e-01 -22.080  &lt; 2e-16 ***
## balance      5.737e-03  2.319e-04  24.738  &lt; 2e-16 ***
## studentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** 
## income       3.033e-06  8.203e-06   0.370  0.71152    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2920.6  on 9999  degrees of freedom
## Residual deviance: 1571.5  on 9996  degrees of freedom
## AIC: 1579.5
## 
## Number of Fisher Scoring iterations: 8</code></pre>
</div>
<div id="noteworthy" class="section level1">
<h1><span class="header-section-number">5</span> Noteworthy</h1>
<p>In the process of doing our diligence on the model, an interesting confound presented itself.
When fitting the student status parameter against default, the coefficent for our model is a positive value, implying that student status increases default. When fitting all parameters in our model, the value becomes negative, implying that student status reduces the probability of default.</p>
<p>How can this be?</p>
<pre class="r"><code># single x model
my_logit2 &lt;- glm(default~student, family= &quot;binomial&quot;, data = Default)
summary(my_logit2)$coef</code></pre>
<pre><code>##               Estimate Std. Error    z value     Pr(&gt;|z|)
## (Intercept) -3.5041278 0.07071301 -49.554219 0.0000000000
## studentYes   0.4048871 0.11501883   3.520181 0.0004312529</code></pre>
<pre class="r"><code># complex model
summary(my_logit)$coef</code></pre>
<pre><code>##                  Estimate   Std. Error    z value      Pr(&gt;|z|)
## (Intercept) -1.086905e+01 4.922555e-01 -22.080088 4.911280e-108
## balance      5.736505e-03 2.318945e-04  24.737563 4.219578e-135
## studentYes  -6.467758e-01 2.362525e-01  -2.737646  6.188063e-03
## income       3.033450e-06 8.202615e-06   0.369815  7.115203e-01</code></pre>
<p>Looking at the plot below, the data suggests that balance and student status are correlated. Therefore, it might be appropriate to offer the following interpretation: students tend to have higher balances than non-students, so even though a given student has a lesser probability of default than a non student, (for a fixed balance) because students tend to carry higher balances overall, students tend to have higher, overall default rates.</p>
<pre class="r"><code>ggplot(Default) + aes(x = student, y = balance, color=student) +
  geom_boxplot(outlier.colour=&quot;red&quot;, outlier.shape=2,
                outlier.size=1) </code></pre>
<p><img src="figure/boxplot%20credit_balance_student-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="model-cross-validation" class="section level1">
<h1><span class="header-section-number">6</span> Model Cross Validation</h1>
<p>Just as important as it is to choose a model that fits the parameters correctly, it is even more so to test the predictive power of the chosen model. To do so, I chose to perform: 1) validation set verification and 2) K-fold cross-validation set with 3, 5, and 10 folds. The results of the validation set are below:</p>
<pre class="r"><code>set.seed(1)

# Create a sample of 5000 observations
train &lt;- sample(10000,5000)

# Defaultx is a subset of the Default data that does not include the training data that we will fit the model on 
Defaultx &lt;- Default[-train,]

# Fit the logistic model using the training data.  
glm.fit &lt;- glm(default~ balance + student, data = Default, family = binomial, subset = train)

# Use the logistic model to fit the same logistic model, but use the test data.  
glm.probs &lt;- predict(glm.fit, Defaultx, type = &quot;response&quot;)

# Make a vector that contains 5000 no responses.   
glm.pred &lt;- rep(&quot;No&quot;, 5000)

# Replace the no reponsees in the glm.pred vector where the probability is greater than 50% with &quot;Yes&quot;
glm.pred[glm.probs &gt; .5] = &quot;Yes&quot;

# Create a vector that contains the defaults from the testing data set, Defaultx
defaultVector &lt;- Defaultx$default 


# Calculate the mean of the values where the predicted value from the training equals the held out set.  
mean(glm.pred == defaultVector)</code></pre>
<pre><code>## [1] 0.974</code></pre>
<p>Using the technique above we can see that ~97.14% of the observations in the test set were classified correctly using the logistic model training set. As this is just one of a variety of validation methods, for technical completeness, below we also implement a K-Fold cross validation set:</p>
<pre class="r"><code># Seed the random number generator 
set.seed(2)

# Fit a logistic model using default and income values
glm.fit1 &lt;- glm(default~balance + student, data = Default, family = binomial)

# Create a vector with three blank values
cv.error &lt;- rep(0,3)


# Store the results of each K  validation set into cv.error.  Use K= {3,5,10} 
cv.error[1] &lt;- cv.glm(Default, glm.fit1, K=3)$delta[1]
cv.error[2] &lt;- cv.glm(Default, glm.fit1, K=5)$delta[1]
cv.error[3] &lt;- cv.glm(Default, glm.fit1, K=10)$delta[1]

1- mean(cv.error) </code></pre>
<pre><code>## [1] 0.9786059</code></pre>
<p>We interpret the value of (1-mean(error)) to be the average of the correctly validated observations of the data set using the K-Folds technique. The results of this are also promising! We can see that again approximately 97% of values were correctly classified using our method.</p>
</div>
<div id="parameter-selection" class="section level1">
<h1><span class="header-section-number">7</span> Parameter Selection</h1>
<p>To reinforce our selection of balance and student status (while excluding income) I fit a cross validation model on all parameters including income. If our methods are correct, adding the income parameter should increase the test error and reduce the correct qualification % of our model.</p>
<pre class="r"><code># Set up the random number generator so that others can repeat results
set.seed(1)

# Create a sample of 5000 observations
train &lt;- sample(10000,5000)

# Defaultx is a subset of the Default data that does not include the training data that
# we will fit the model on 
Defaultx &lt;- Default[-train,]

# Fit the logistic model using the training data.  
glm.fit &lt;- glm(default~income + balance + student, data = Default, family = binomial, subset = train)

# Use the logistic model to fit the same logistic model, but use the test data.  
glm.probs &lt;- predict(glm.fit, Defaultx, type = &quot;response&quot;)

# Make a vector that contains 5000 no responses.   
glm.pred &lt;- rep(&quot;No&quot;, 5000)

# Replace the no reponsees in the glm.pred vector where the probability is greater than 50% with &quot;Yes&quot;
glm.pred[glm.probs &gt; .5] = &quot;Yes&quot;

# Create a vector that contains the defaults from the testing data set, Defaultx
defaultVector &lt;- Defaultx$default 


# Calculate the mean of the values where the predicted value from the training equals the held out set.  
mean(glm.pred == defaultVector)</code></pre>
<pre><code>## [1] 0.974</code></pre>
<p>As predicted, fitting the model and including the income parameter increased the test error in the validation set and reduces the probability of the correct classification.</p>
</div>
